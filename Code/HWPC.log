---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  C:\Users\ricar\Dropbox\Apps\GitHub\Monetary-Policy-and-the-Wage-Inflation-Unemployment-Tradeoff\Code\HWPC.log
  log type:  text
 opened on:   3 Apr 2023, 13:40:06

. clear all

. set more off

. set scheme s1color

. graph set window fontface "Linux Biolinum O"        // set default font (window)

. graph set window fontfacesans "Linux Biolinum O"    // set default sans font (window)

. graph set window fontfaceserif "Linux Libertine O"  // set default serif font (window)

. graph set window fontfacemono "DejaVu Sans Mono"    // set default mono font (window)

. 
. 
. ********************************************************************************
. * Control Panel
. ********************************************************************************
. 
. * Master - choose number of horizons for the IRFs
. global hf               = 10

. 
. * Choose number of horizons for the quarterly IRFs
. global hfq              = 40

. 
. * Master - choose number of lags for the IRFs
. global lags     = 2

. global lagsq    = 4

. 
. * Master - use matched sample (that is, all horizons with same # obs)
. global match    = 1

. 
. * Master - estimation of AR conf bands: set number of gridpoints and conf level
. global gridd    = 100

. global levell   = 90

. 
. * Master - choose whether outlier is identified when wage inflation is above 50% in absolute value (fifty=1)
. *                  or when it is either in top or bottom 1% of the sample (fifty=0) - robustness check
. global fifty    = 1

. 
. * Master - produce figure for slides (slides==1) or for paper (slides==0)
. global slides   = 0

. 
. * Master - asymmetry specifications, choose one at a time from the following list
.         * lowflat       -       low vs high cpi inflation
.         * boombust      -       bust vs boom in the economy (negative or positive unemployment gap using an hp filter)
.         * negpos        -       negative vs positive change in short run interest rate 
.         * tradeoc       -       degree of trade openess (more vs less) measured by having more than 40% of (imports+exports) / gdp (40% is close to mean and median)
.         * capitaloc     -       degree of capital openess (open vs close) measured as in Quinn et al. (2011)
.         * postwar   -   d
. global state    = "lowflat"

. ********************************************************************************
. 
. /*
> * Prepare Data with all observations
> global wage_out = 0
> do Data_Management
> 
> * Produce descriptive statistics
> ** Table 1 + Table A.2 + Table A.3
> do Descriptives
> 
> ** Figure 1
> do Figure_1
> 
> *** Main Analysis
> 
> * Prepare Data without wage variable for outliers and war periods 
> global wage_out = 1
> do Data_Management
> 
> *Produce Rolling Window graphs
> * Figure 2
> do Figure_2
> 
> * First Stage Results of Monetary Policy Shocks (Trilemma Instrumental Variable)
> ** Table 3
> do First_Stage                  
> 
> 
> * Phillips Multiplier
> ** Figures 3 a) and 3 b)
> do PM_BM
> 
> 
> ** Figure 3 c)
> do MP_IRFs_BM
> 
> ** Figure A.1
> * Effects of Monetary Policy (as in JST 2020)
> do MP_IRFs
> 
> * State Dependent Phillips Multipliers
> * Figure 5 and Table A.7
> do SD_BM
> 
> 
> * Figure 4
> global state    = "postwar"
> do SD_BM
> 
> 
> *** Other Figures in Appendix 
> * Figure A.2 and Table A.6 (unmatched 15 years)
> global hf = 15
> global match = 0
> global state    = "lowflat"
> do SD_BM
> 
> */
. *******************************************************************************
. * Quarterly analysis
. global match = 1

. global wage_out = 1

. do Data_Management_Quarter

.                                         *** Data Management Quarterly ***
. 
. * List of country codes: AU BE CA DK FI FR DE IE IT JP NL NO PT ES SE GB US
.                                 
.                                         
. * Import data from FRED date range 1995Q1-2020Q1; when monthly agg to quarter
. 
. *quietly{
. 
. 
. 
. /*
> ********************************************************************************
> *                                                                  Wages
> * Hourly Earnings: Private Sector (LCEA)
> * Hourly Wage Rate: Private Sector for the Netherlands and Australia (LCWR)
> ********************************************************************************
> import fred LCEAPR01SEQ189N LCEAPR01ITQ661S LCEAPR01USQ189S LCEAPR01FRQ661S ///
> LCWRPR01NLQ661S LCEAPR01IEQ661S LCEAPR01PTQ661S LCEAMN01CAQ189S LCEAPR01BEQ661S ///
> LCEAMN03NOQ661N LCEAPR03JPQ661S LCEAPR01FIQ661S LCEAPR01DKQ661S LCEAPR01DEQ661S ///
> LCEATT01ESQ189N LCEAPR02GBQ661S LCWRTT01AUQ661N ///
> , daterange(1995-01-01 2020-01-01) aggregate(quarterly,avg) long clear
> 
> * Country Name (9 and 10 character)
> gen country = substr(series_id,9,2)
> 
> * Seasonally adjusted (N: not seasonally adjusted; S: seasonally adjusted)
> gen seasonal_wage = substr(series_id,15,1)
> 
> * change name of the series and store as .dta file
> rename value wage
> tempfile wage
> save `wage'
> 
> 
> ********************************************************************************
> *                                                         Interest Rates
> * 3-Month or 90-day Rates and Yields: Interbank Rates
> * Immediate Rates: Less than 24 Hours: Call Money/Interbank Rate for Japan
> ********************************************************************************
> import fred IR3TIB01AUQ156N IR3TIB01BEQ156N IR3TIB01CAQ156N IR3TIB01DKQ156N ///
> IR3TIB01FIQ156N IR3TIB01FRQ156N IR3TIB01DEQ156N IR3TIB01IEQ156N IR3TIB01ITQ156N ///
> IRSTCI01JPQ156N IR3TIB01NLQ156N IR3TIB01NOQ156N IR3TIB01PTQ156N IR3TIB01ESQ156N ///
> IR3TIB01SEQ156N IR3TIB01GBQ156N IR3TIB01USQ156N ///
> , daterange(1995-01-01 2020-01-01) aggregate(quarterly,avg) long clear
> 
> * Country Name (9 and 10 character)
> gen country = substr(series_id,9,2)
> 
> * Seasonally adjusted (N: not seasonally adjusted; S: seasonally adjusted)
> gen seasonal_stir = substr(series_id,15,1)
> 
> * change name of the series and store as .dta file
> rename value stir
> tempfile stir
> save `stir'
> 
> 
> 
> ********************************************************************************
> *                                                                       GDP
> * Real Gross Domestic Product
> ********************************************************************************
> import fred NGDPRSAXDCAUQ CLVMNACSCAB1GQBE NGDPRSAXDCCAQ CLVMNACSCAB1GQDK ///
> CLVMNACSCAB1GQFI CLVMNACSCAB1GQFR CLVMNACSCAB1GQDE CLVMNACNSAB1GQIE CLVMNACSCAB1GQIT ///
> JPNRGDPEXP CLVMNACSCAB1GQNL CLVMNACSCAB1GQNO CLVMNACSCAB1GQPT CLVMNACSCAB1GQES ///
> CLVMNACSCAB1GQSE CLVMNACSCAB1GQUK GDPC1 ///
> , daterange(1995-01-01 2020-01-01) aggregate(quarterly,avg) long clear
> 
> * Country Name
> gen country = substr(series_id,15,2)
> replace country = substr(series_id,11,2) if substr(series_id,1,3) == "NGD"
> replace country = "JP" if series_id == "JPNRGDPEXP"
> replace country = "US" if series_id == "GDPC1"
> replace country = "GB" if country == "UK"
> 
> * Seasonally adjusted (N: not seasonally adjusted; S: seasonally adjusted)
> gen seasonal_gdp = "S"
> replace seasonal_gdp = "N" if country == "IE"
> 
> * change name of the series and store as .dta file
> rename value gdp
> tempfile gdp
> save `gdp'
> 
> 
> ********************************************************************************
> *                                                       Consumer Price Index
> ********************************************************************************
> import fred AUSCPIALLQINMEI BELCPIALLQINMEI CPALCY01CAM661N DNKCPIALLQINMEI ///
> FINCPIALLQINMEI FRACPIALLQINMEI DEUCPIALLQINMEI IRLCPIALLQINMEI ITACPIALLQINMEI ///
> JPNCPIALLQINMEI NLDCPIALLQINMEI NORCPIALLQINMEI PRTCPIALLQINMEI ESPCPIALLQINMEI ///
> SWECPIALLQINMEI GBRCPIALLQINMEI USACPIALLQINMEI ///
> , daterange(1995-01-01 2020-01-01) aggregate(quarterly,avg) long clear
> 
> * Country Name
> gen country = substr(series_id,1,2)
> replace country = "CA" if country == "CP"
> replace country = "DK" if country == "DN"
> replace country = "IE" if country == "IR"
> replace country = "PT" if country == "PR"
> replace country = "SE" if country == "SW"
> 
> * Seasonally adjusted (N: not seasonally adjusted; S: seasonally adjusted)
> gen seasonal_cpi = "N"
> 
> * change name of the series and store as .dta file
> rename value cpi
> tempfile cpi
> save `cpi'
> 
> 
> ********************************************************************************
> *                                                       Unemployment Rates
> *Harmonised Unemployment Rates: Total: All Persons 
> ********************************************************************************
> import fred LRHUTTTTAUQ156S LRHUTTTTBEQ156S LRHUTTTTCAQ156S LRHUTTTTDKQ156S ///
> LRHUTTTTFIQ156S LRHUTTTTFRQ156S LRHUTTTTDEQ156S LRHUTTTTIEQ156S LRHUTTTTITQ156S ///
> LRHUTTTTJPQ156S LRHUTTTTNLQ156S LRHUTTTTNOQ156S LRHUTTTTPTQ156S LRHUTTTTESQ156S ///
> LRHUTTTTSEQ156S LRHUTTTTGBQ156S LRHUTTTTUSQ156S ///
> , daterange(1995-01-01 2020-01-01) aggregate(quarterly,avg) long clear
> 
> * Country Name (9 and 10 character)
> gen country = substr(series_id,9,2)
> 
> * Seasonally adjusted (N: not seasonally adjusted; S: seasonally adjusted)
> gen seasonal_unemp = substr(series_id,15,1)
> 
> * change name of the series and store as .dta file
> rename value unemp
> tempfile unemp
> save `unemp'
> 
> 
> ********************************************************************************
> *                                                       Quarterly Dataset
> ********************************************************************************
> 
> * Merge different variables
> foreach var in wage cpi stir gdp {
>         merge 1:1 country daten using ``var''
>         drop _merge
> }
> 
> * Date
> generate dateq = qofd(daten)
> generate quarter = quarter(daten)
> 
> * Cid
> egen id = group(country), label
> 
> * Panel data
> xtset id dateq, quarter
> 
> 
> * remove seasonality from not seasonally adjusted series (wages for group and gdp for Ireland)
> foreach var in wage gdp {
>         by id:  hprescott `var', stub(hp) smooth(100)
>         egen double hpsmm = rowtotal(hp_`var'_sm_*)
>         replace `var' = hpsmm if seasonal_`var' == "N"
>         drop hp_`var'_* hp_`var'_sm_* hpsmm
> }
> 
> * Index to 2015-01-01 = 100 for comparability?
> * ?
> 
> * add capital openess variable under the assumption it does not change within the same year
> gen year = substr(datestr,1,4)
> destring year, replace
> merge m:1 country year using "$hp\Data\openquinn_extended_IRL.dta"
> drop if _merge == 2
> drop _merge
> xtset id dateq, quarter
> replace iso = iso[_n-1] if id==id[_n-1]
> 
> * drop unnecessary variables
> drop daten datestr seasonal_* country series_id
> 
> * save FRED data
> save "$hp\Data\FRED_Imported.dta", replace
> */
. 
. use "$hp\Data\FRED_Imported.dta", clear

. 
. * get peg definitions from yearly data from JST (2020)
. preserve

. use "$hp\Data\JSTdataset_v100.dta", clear

. keep year iso peg peg_base peg_type

. tempfile JST

. save `JST'
file C:\Users\ricar\AppData\Local\Temp\ST_3674_000002.tmp saved

. restore

. 
. * merge with quarterly data
. merge m:1 iso year using `JST'

    Result                           # of obs.
    -----------------------------------------
    not matched                         2,276
        from master                         0  (_merge==1)
        from using                      2,276  (_merge==2)

    matched                             1,717  (_merge==3)
    -----------------------------------------

. drop if _merge == 2
(2,276 observations deleted)

. drop _merge

. 
. xtset id dateq, quarter
       panel variable:  id (strongly balanced)
        time variable:  dateq, 1995q1 to 2020q1
                delta:  1 quarter

. 
. ********************************************************************************
. * Creation of control variables
. ********************************************************************************
.                                 
. * price inflation (growth rate of cpi) in % year on year (yoy)
. gen dpyoy = cpi/l4.cpi-1
(68 missing values generated)

. replace dpyoy=dpyoy*100
(1,647 real changes made)

. label var dpyoy "Price inflation (%) yoy"

. 
. gen dp = cpi/l1.cpi-1
(17 missing values generated)

. replace dp=dp*100
(1,670 real changes made)

. gen ldp = l.dp
(34 missing values generated)

. label var dp "Price inflation (%)"

. 
. * wage inflation (growth rate of wage index) in %
. gen dwn = wage/l1.wage-1
(114 missing values generated)

. replace dwn=dwn*100
(1,590 real changes made)

. label var dwn "Wage inflation (%)"

. 
. * unemployment                                  
. label var unemp "Unemployment rate"

. 
. * world GDP growth following JST (2020)
. sort dateq

. by dateq: egen countgdp = count(gdp)  

. by dateq: egen sumGDP = sum(gdp)

. 
. * correcting for artificial growth coming from potential missing observations
. replace sumGDP = sumGDP / countgdp
(1,717 real changes made)

. label var sumGDP "World GDP"

. 
. 
. ********************************************************************************
. * List unstable periods and outliers in the sample 
. ********************************************************************************
. 
. * Hyperinflation in Germany (1920 to 1925)
. gen hyper=0

. replace hyper=1 if iso=="DEU" & year>=1920 & year<=1925
(0 real changes made)

. 
. * War periods
. gen war = 0

. replace war = 1 if year>=1914 & year<=1919
(0 real changes made)

. replace war = 1 if year>=1939 & year<=1945
(0 real changes made)

. 
. 
. * Identify extreme (outlier) values in the dependent variable (dwn)
. gen outlier=0

. 
. if ($fifty ==1) {
. * if absolute value of wage inflation is above 50%
. replace outlier = 1 if abs(dwn)>50
(114 real changes made)
. }

. else if ($fifty ==0) {
. * alternatively, truncate top 1% and bottom 1% (rob check)
. xtile pct = dwn, nq(100)
. replace outlier = 1 if pct <= 1
. replace outlier = 1 if pct >= 100
. drop pct
. }

. 
. * include hyperinflation in Germany
. replace outlier = . if dwn == .
(114 real changes made, 114 to missing)

. replace outlier = 1 if hyper == 1
(0 real changes made)

. 
. 
. * in order to properly remove the outlier values from the main analysis 
. * replace wage variable by missing value
. if ($wage_out ==1) {
.         replace wage = . if war==1 | outlier==1
(0 real changes made)
. }

. 
. * Create a matched sample dummy (i.e. for which there is data for both wages and unemployment)
. gen noval=0

. replace noval=1 if unemp==. | dwn==.
(114 real changes made)

. 
. 
. ********************************************************************************
. * Creation of control variables (must come after replace wage by missing values for outliers)
. ********************************************************************************
. 
. 
. * Taking Logs (following JST (2020) JME)
. gen lunemp      = 100*log(1+unemp)                      // unemployment rate

. gen lwage       = 100*log(1+wage)                       // wage index
(97 missing values generated)

. gen lsumgdp = 100*log(sumGDP)                   // (sample) "world" GDP

. gen lrgdp   = 100*log(gdp)                              // real GDP
(4 missing values generated)

. gen lcpi    = 100*log(cpi)                              // price index

. 
. 
. /*
> gen lriy        = 100*log(iy*rgdpbarro)         // investment
> gen loansgdp = tloans/gdp*100                   // loans to gdp ratio
> gen lspreal = log(stock/cpi)                    // real stock prices index
> gen cay         = 100*(ca/gdp)                          // current account to gdp ratio
> gen lrcon   = 100*log(rconsbarro)               // real consumption index from Barro
> */
. 
. * Taking Differences
. xtset id dateq, quarter
       panel variable:  id (strongly balanced)
        time variable:  dateq, 1995q1 to 2020q1
                delta:  1 quarter

. local varlist lrgdp lwage lsumgdp lcpi stir lunemp unemp 

. *ltrate lspreal loansgdp  cay lrcon lriy 
. foreach var in `varlist'{ 
  2.         gen d`var' = d.`var'
  3. }
(21 missing values generated)
(114 missing values generated)
(17 missing values generated)
(17 missing values generated)
(17 missing values generated)
(17 missing values generated)
(17 missing values generated)

. 
.         gen dlcpi_yoy = 100*log(cpi)-100*log(l4.cpi)
(68 missing values generated)

. 
. 
. ********************************************************************************
. * Preparing State-Dependencies (output and unemployment gaps)
. ********************************************************************************
. /*
> **** 1) output gap 
> cap drop hpsm
> sort iso
> by iso: hprescott gdp, stub(hp) smooth(100)
> egen double hpsm = rowtotal(hp_gdp_sm_*)
> drop hp_gdp_sm_*
> gen outgap=(1-hpsm/gdp)
> 
> 
> **** 2) unemployment gap
> 
> * by country replace missing unemployment gaps by average across entire sample
> gen unempp=unemp
> forvalues x=1/18{
>         sum unemp if id==`x'
>         replace unempp = r(mean) if id==`x' & unemp ==.
> }
> 
> cap drop hpsmm
> sort iso
> by iso:  hprescott unempp, stub(hp) smooth(100)
> egen double hpsmm = rowtotal(hp_unempp_sm_*)
> drop hp_unempp_sm_*
> gen unempgap=(1-hpsmm/unemp)
> */
. 
. ********************************************************************************
. * Instrument construction
. ********************************************************************************
. do trilemma_iv_Quarter

. /*
> trilemma_iv.do
> 
> Here, I follow the code from Jordà, Schularick, and Taylor (2020) JME 
> to re-construct the trilemma instrument until 2020.
> */ 
. 
. *quietly{
. 
. **************************************************************************
. * CONSTRUCT THE INSTRUMENTAL VARIABLE 
. **************************************************************************
.         
. * extended Ireland capital openess variable (assume from 1960 onwards same capital openess as the UK) - waiting on data from Dennis Quinn to confirm this
. * extend dataset until 2020 (according to their classification all countries in this dataset are today with capital openess = 100)
. replace openquinn = 100 if year >2012
(493 real changes made)

. 
. 
. ********* MAKE BASE INTEREST RATE DATA
. 
. * collect ibase data for DEU/USA
. 
. preserve

. keep iso dateq stir

. keep if iso=="USA"
(1,616 observations deleted)

. keep dateq stir

. rename stir stir_usa

. sort dateq

. save ../Data/stir_usa.dta, replace
file ../Data/stir_usa.dta saved

. restore

. 
. preserve

. keep iso dateq stir

. keep if iso=="DEU"
(1,616 observations deleted)

. keep dateq stir

. rename stir stir_deu

. sort dateq

. save ../Data/stir_deu.dta, replace
file ../Data/stir_deu.dta saved

. restore

. 
. 
. cap drop _merge

. sort dateq

. merge m:1 dateq using ../Data/stir_usa.dta // JST us rate

    Result                           # of obs.
    -----------------------------------------
    not matched                             0
    matched                             1,717  (_merge==3)
    -----------------------------------------

. drop _merge

. sort dateq

. merge m:1 dateq using ../Data/stir_deu.dta // JST deu rate

    Result                           # of obs.
    -----------------------------------------
    not matched                             0
    matched                             1,717  (_merge==3)
    -----------------------------------------

. drop _merge

. xtset id dateq
       panel variable:  id (strongly balanced)
        time variable:  dateq, 1995q1 to 2020q1
                delta:  1 quarter

. 
. *erase ../Data/stir_usa.dta
. *erase ../Data/stir_deu.dta
. 
. ********** 1. Make IV using the raw change in the base country interest rate
. ********** IV dibpeg = dibase*peg 
. 
. * force sort tsset again
. xtset id dateq, quarter
       panel variable:  id (strongly balanced)
        time variable:  dateq, 1995q1 to 2020q1
                delta:  1 quarter

. 
. * use base coding from JST dataset
. capture drop dibase

. gen      dibase = .
(1,717 missing values generated)

. replace  dibase = d.stir_usa   if peg_base=="USA"
(400 real changes made)

. replace  dibase = d.stir_deu   if peg_base=="DEU"
(1,200 real changes made)

. 
. 
. * IV is impulse to short rate due to change in base when pegged in year T and T-1
. capture drop dibpeg

. gen     dibpeg = dibase * peg * l.peg  
(117 missing values generated)

. replace dibpeg = dibpeg * (openquinn/100)  // scale by quinn capital openness
(148 real changes made)

. replace dibpeg = . if peg==0 | l.peg==0
(634 real changes made, 634 to missing)

. 
. 
. 
. ********** 2. Make IV using the residualized change in the base country interest rate
. ********** IV dibpegF = dibaseF*peg (without R&R forecast for base countries - here it is about peg regimes)
. 
. **************************************************************************
. ******** CONSTRUCT THE INSTRUMENTAL VARIABLE                      ********
. ********  USING TAYLOR RULE RESIDS OR FACTOR AUGMENTATION         ********
. **************************************************************************
. 
. * force sort tsset again
. xtset id dateq, quarter
       panel variable:  id (strongly balanced)
        time variable:  dateq, 1995q1 to 2020q1
                delta:  1 quarter

. estimates clear                                         

. 
. * forecasting equation = regressor list uses 4 lags of RHS (reduced version from
. *  yearly data) - l.dlrcon l.dltrate l.dstir l.dlrgdp l.dlcpi l.dlriy l.cay
. local rhsstirF L(1/4).dlrgdp L(1/4).dstir L(1/4).dlcpi

. 
. cap drop dstir_hat

. gen dstir_hat =.
(1,717 missing values generated)

. 
. * forecast stir
. xtreg d.stir `rhsstirF' if (iso=="DEU"|iso=="USA"), fe

Fixed-effects (within) regression               Number of obs     =        192
Group variable: id                              Number of groups  =          2

R-sq:                                           Obs per group:
     within  = 0.4440                                         min =         96
     between = 1.0000                                         avg =       96.0
     overall = 0.4435                                         max =         96

                                                F(12,178)         =      11.84
corr(u_i, Xb)  = -0.0355                        Prob > F          =     0.0000

------------------------------------------------------------------------------
      D.stir |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      dlrgdp |
         L1. |   .1066036   .0342321     3.11   0.002     .0390507    .1741566
         L2. |   .0414355   .0355082     1.17   0.245    -.0286358    .1115068
         L3. |  -.0041053   .0357537    -0.11   0.909     -.074661    .0664504
         L4. |   .0231017   .0354628     0.65   0.516      -.04688    .0930834
             |
       dstir |
         L1. |   .4317721   .0799099     5.40   0.000     .2740795    .5894648
         L2. |  -.0533472   .0863042    -0.62   0.537    -.2236583    .1169639
         L3. |   .0457448     .08607     0.53   0.596    -.1241041    .2155937
         L4. |   .0117863   .0741548     0.16   0.874    -.1345494     .158122
             |
       dlcpi |
         L1. |   .1517525   .0475255     3.19   0.002     .0579665    .2455384
         L2. |  -.1604093   .0470863    -3.41   0.001    -.2533284   -.0674901
         L3. |  -.0205628   .0481319    -0.43   0.670    -.1155454    .0744197
         L4. |   -.113552   .0484565    -2.34   0.020     -.209175   -.0179289
             |
       _cons |  -.0366625   .0570074    -0.64   0.521    -.1491598    .0758348
-------------+----------------------------------------------------------------
     sigma_u |  .01202631
     sigma_e |  .29513737
         rho |  .00165766   (fraction of variance due to u_i)
------------------------------------------------------------------------------
F test that all u_i=0: F(1, 178) = 0.12                      Prob > F = 0.7248

. cap drop temp

. predict temp if (iso=="DEU"|iso=="USA")
(option xb assumed; fitted values)
(1,525 missing values generated)

. replace dstir_hat = temp if (iso=="DEU"|iso=="USA")
(192 real changes made)

. 
. * make the residualized change in stir that will be the basis for the IV
. cap drop dstir_resid

. gen dstir_resid = d.stir - dstir_hat
(1,525 missing values generated)

. 
. * copy into new series
. cap drop dibaseF_usa dibaseF_gbr dibaseF_deu dibaseF_fra

. gen dibaseF_usa = dstir_resid if iso=="USA"  // dibase for new IV
(1,621 missing values generated)

. gen dibaseF_deu = dstir_resid if iso=="DEU"  // dibase for new IV
(1,621 missing values generated)

. 
. 
. cap drop temp

. bysort dateq: egen temp = mean(dibaseF_usa)
(85 missing values generated)

. replace dibaseF_usa = temp
(1,536 real changes made)

. cap drop temp

. bysort dateq: egen temp = mean(dibaseF_deu)
(85 missing values generated)

. replace dibaseF_deu = temp
(1,536 real changes made)

. drop temp

. 
. 
. * make the IV, same as standard trilemma IV (use composite GBR-USA-FRA for interwar)
. xtset id dateq
       panel variable:  id (strongly balanced)
        time variable:  dateq, 1995q1 to 2020q1
                delta:  1 quarter

. 
. 
. * use base coding from JST dataset and replicate hybrid construction of OST
. cap drop dibaseF

. gen      dibaseF = .
(1,717 missing values generated)

. replace  dibaseF = dibaseF_usa   if peg_base=="USA"
(384 real changes made)

. replace  dibaseF = dibaseF_deu   if peg_base=="DEU"
(1,152 real changes made)

. 
. 
. *****************
. * impulse to short rate due to change in base when pegged in year T and T-1
. cap drop dibpegF

. gen      dibpegF = .
(1,717 missing values generated)

. replace  dibpegF = dibaseF * peg * l.peg  
(1,536 real changes made)

. replace  dibpegF = dibpegF * (openquinn/100)  // scale by quinn capital openness
(135 real changes made)

. replace  dibpegF = . if peg==0 | l.peg==0
(610 real changes made, 610 to missing)

. 
. * replace original JST estimates by these new ones
. gen JSTtrilemmaIV       = dibpeg
(751 missing values generated)

. gen JSTtrilemmaIV_R = dibpegF
(791 missing values generated)

. label var JSTtrilemmaIV   "JST trilemma instrument (raw base rate changes)"

. label var JSTtrilemmaIV_R  "JST trilemma instrument (residualized base rate changes)"

. 
. 
. *****************
. *  save trilemma IVs in their own file
. preserve

. keep      dateq iso JSTtrilemmaIV JSTtrilemmaIV_R peg peg_type peg_base

. order     dateq iso JSTtrilemmaIV JSTtrilemmaIV_R peg peg_type peg_base

. label var peg_type "Peg type: BASE, PEG, or FLOAT"

. label var peg_base "Peg base: GBR, USA, or DEU"

. sort iso dateq

. save  ../Data/JSTtrilemmaIV2_Quarter.dta , replace
file ../Data/JSTtrilemmaIV2_Quarter.dta saved

. restore

. 
. *}
. 
end of do-file

. 
. *}
. 
. ********************************************************************************
. * Saving the Data
. ********************************************************************************
. xtset id dateq, quarter
       panel variable:  id (strongly balanced)
        time variable:  dateq, 1995q1 to 2020q1
                delta:  1 quarter

. drop if dateq==240
(17 observations deleted)

. save "$hp\Data\Data_Analysis_Quarter.dta", replace
file C:\Users\ricar\Dropbox\Apps\GitHub\Monetary-Policy-and-the-Wage-Inflation-Unemployment-Tradeoff\\Data\Data_Analysis_Quarter.dta saved

. 
end of do-file

. 
. * First Stage Results of Monetary Policy Shocks (Trilemma Instrumental Variable)
. *do First_Stage_Quarter
. 
. * Phillips Multiplier Quarterly Data
. ** Figures 3 a) and 3 b)
. *do PM_BM_Quarter
. 
. ** Figure 3 c)
. *do MP_IRFs_BM_Quarter
. 
. 
. * State Dependent Phillips Multipliers
. * Figure ?? and Table ??
. global state    = "lowflat"

. do SD_BM_Quarter

. /*
> State Dependencies - Monetary Policy and the Wage-Inflation Unemployment Trade-off
> 
> SD Phillips Multiplier and IRFs close to Barnichon and Mesters (2020):
> Adding two lags of unemployment and wage inflation but also country 
> fixed effects and global gdp growth.
> 
> Author: Ricardo Duque Gabriel
> First Date: 15/11/2020
> Last Update: 31/03/2023
> 
> Calls SD_BM_Reg.do and Sd_BM_Graphs.do to produce Figures 3 and A.3 and table A.4
> according to different specifications as called in Master.do file
> 
> */
. 
. clear all

. 
. * Upload data
. use "$hp\Data\Data_Analysis_Quarter.dta", clear

. 
. 
. * Call chosen state
. local s1 $state

. 
. * Log from here
. cap log close
